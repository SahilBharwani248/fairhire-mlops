{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model B: AutoML for Recruiter Decision Classification\n",
        "\n",
        "Trains Model A using AutoML (PyCaret) to predict **Recruiter Decision (Hire/Reject)** based on resume features.\n",
        "\n",
        "## Model B Specifications:\n",
        "- **Input Features**: All resume features (Skills, Experience, Education, Certifications, Job Role, Salary, Projects)\n",
        "- **Excluded**: Demographic features (Gender, Race, Age, Disability_Status) - NOT used in training\n",
        "- **Target Variable**: Recruiter_Decision (Hire/Reject) - **Classification Task**\n",
        "- **Purpose**: This model acts as the company's hiring model we are testing for fairness\n",
        "\n",
        "## What we'll do:\n",
        "1. Load processed data from Data_processing.ipynb\n",
        "2. Set up PyCaret AutoML for classification\n",
        "3. Train and compare multiple models\n",
        "4. Evaluate metrics (Accuracy, Precision, Recall, F1, AUC)\n",
        "5. Save the best model and metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n",
            "PyCaret version: 3.3.2\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import json\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# PyCaret for AutoML\n",
        "from pycaret.classification import *\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"PyCaret version: {__import__('pycaret').__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Processed Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading processed data from CSV files...\n",
            "✓ Loaded demographics files for fairness metrics\n",
            "\n",
            "✓ Successfully loaded all processed data from CSV files!\n",
            "\n",
            "Training set shape: (800, 7)\n",
            "Test set shape: (200, 7)\n",
            "\n",
            "Feature columns: ['Skills', 'Experience', 'Education_Ordinal', 'Certifications_Encoded', 'Job_Role_Encoded', 'Salary_Expectation', 'Projects_Count']\n",
            "\n",
            "Target variable (Recruiter_Decision) distribution:\n",
            "Recruiter_Decision\n",
            "Hire      646\n",
            "Reject    154\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class balance: {'Hire': 0.8075, 'Reject': 0.1925}\n"
          ]
        }
      ],
      "source": [
        "# Load processed data from saved CSV files\n",
        "print(\"Loading processed data from CSV files...\")\n",
        "\n",
        "try:\n",
        "    # Load training and test features\n",
        "    X_train = pd.read_csv('model_B/X_train_modelB.csv')\n",
        "    X_test = pd.read_csv('model_B/X_test_modelB.csv')\n",
        "    \n",
        "    # Load target variables (Recruiter_Decision) \n",
        "    y_train_df = pd.read_csv('model_B/y_train_modelB.csv')\n",
        "    y_test_df = pd.read_csv('model_B/y_test_modelB.csv')\n",
        "    y_train = y_train_df['Recruiter_Decision'].squeeze()  \n",
        "    y_test = y_test_df['Recruiter_Decision'].squeeze()   \n",
        "    \n",
        "    # Load demographics for fairness metrics (optional, for later use)\n",
        "    try:\n",
        "        demographics_train = pd.read_csv('model_B/demographics_train_modelB.csv')\n",
        "        demographics_test = pd.read_csv('model_B/demographics_test_modelB.csv')\n",
        "        print(\"✓ Loaded demographics files for fairness metrics\")\n",
        "    except FileNotFoundError:\n",
        "        demographics_train = None\n",
        "        demographics_test = None\n",
        "        print(\"⚠ Demographics files not found (optional for fairness analysis)\")\n",
        "    \n",
        "    print(\"\\n✓ Successfully loaded all processed data from CSV files!\")\n",
        "    print(f\"\\nTraining set shape: {X_train.shape}\")\n",
        "    print(f\"Test set shape: {X_test.shape}\")\n",
        "    print(f\"\\nFeature columns: {list(X_train.columns)}\")\n",
        "    print(f\"\\nTarget variable (Recruiter_Decision) distribution:\")  \n",
        "    print(y_train.value_counts())  \n",
        "    print(f\"\\nClass balance: {y_train.value_counts(normalize=True).to_dict()}\")  \n",
        "    \n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\n Error: Required CSV files not found!\")\n",
        "    print(f\"Missing file: {e.filename if hasattr(e, 'filename') else str(e)}\")\n",
        "    print(\"\\nPlease run Data_processing.ipynb first to generate the processed CSV files.\")\n",
        "    print(\"Required files:\")\n",
        "    print(\"  - X_train.csv, X_test.csv\")\n",
        "    print(\"  - y_train.csv, y_test.csv\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"\\n Error loading data: {e}\")\n",
        "    print(f\"Error type: {type(e).__name__}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape: (800, 8)\n",
            "Test data shape: (200, 8)\n",
            "\n",
            "Target distribution in training data:\n",
            "Recruiter_Decision\n",
            "Hire      646\n",
            "Reject    154\n",
            "Name: count, dtype: int64\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Skills</th>\n",
              "      <th>Experience</th>\n",
              "      <th>Education_Ordinal</th>\n",
              "      <th>Certifications_Encoded</th>\n",
              "      <th>Job_Role_Encoded</th>\n",
              "      <th>Salary_Expectation</th>\n",
              "      <th>Projects_Count</th>\n",
              "      <th>Recruiter_Decision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Python, NLP, Pytorch</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80377</td>\n",
              "      <td>1</td>\n",
              "      <td>Hire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cybersecurity, Networking, Ethical Hacking</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>102929</td>\n",
              "      <td>10</td>\n",
              "      <td>Hire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ethical Hacking, Cybersecurity, Linux</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>66802</td>\n",
              "      <td>1</td>\n",
              "      <td>Reject</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TensorFlow, Pytorch</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>62312</td>\n",
              "      <td>1</td>\n",
              "      <td>Hire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C++, React, Java, SQL</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>99057</td>\n",
              "      <td>8</td>\n",
              "      <td>Hire</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       Skills  Experience  Education_Ordinal  \\\n",
              "0                        Python, NLP, Pytorch           2                  4   \n",
              "1  Cybersecurity, Networking, Ethical Hacking           2                  3   \n",
              "2       Ethical Hacking, Cybersecurity, Linux           6                  3   \n",
              "3                         TensorFlow, Pytorch           2                  2   \n",
              "4                       C++, React, Java, SQL           9                  3   \n",
              "\n",
              "   Certifications_Encoded  Job_Role_Encoded  Salary_Expectation  \\\n",
              "0                       0                 0               80377   \n",
              "1                       0                 1              102929   \n",
              "2                       2                 1               66802   \n",
              "3                       3                 0               62312   \n",
              "4                       3                 3               99057   \n",
              "\n",
              "   Projects_Count Recruiter_Decision  \n",
              "0               1               Hire  \n",
              "1              10               Hire  \n",
              "2               1             Reject  \n",
              "3               1               Hire  \n",
              "4               8               Hire  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Combine X and y for PyCaret setup\n",
        "train_data = X_train.copy()\n",
        "train_data['Recruiter_Decision'] = y_train.values  \n",
        "\n",
        "test_data = X_test.copy()\n",
        "test_data['Recruiter_Decision'] = y_test.values   \n",
        "\n",
        "print(f\"Training data shape: {train_data.shape}\")\n",
        "print(f\"Test data shape: {test_data.shape}\")\n",
        "print(f\"\\nTarget distribution in training data:\") \n",
        "print(train_data['Recruiter_Decision'].value_counts()) \n",
        "print(f\"\\nFirst few rows:\")\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Setup PyCaret AutoML\n",
        "\n",
        "Initialize PyCaret regression environment. This will:\n",
        "- Handle text features (Skills) automatically\n",
        "- Prepare data for modeling\n",
        "- Set up preprocessing pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 154, number of negative: 646\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 323\n",
            "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.192500 -> initscore=-1.433847\n",
            "[LightGBM] [Info] Start training from score -1.433847\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_5b1f1_row10_col1, #T_5b1f1_row16_col1, #T_5b1f1_row18_col1, #T_5b1f1_row20_col1, #T_5b1f1_row22_col1 {\n",
              "  background-color: lightgreen;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_5b1f1\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_5b1f1_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
              "      <th id=\"T_5b1f1_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_5b1f1_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
              "      <td id=\"T_5b1f1_row0_col1\" class=\"data row0 col1\" >42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_5b1f1_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
              "      <td id=\"T_5b1f1_row1_col1\" class=\"data row1 col1\" >Recruiter_Decision</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_5b1f1_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
              "      <td id=\"T_5b1f1_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_5b1f1_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n",
              "      <td id=\"T_5b1f1_row3_col1\" class=\"data row3 col1\" >Hire: 0, Reject: 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_5b1f1_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
              "      <td id=\"T_5b1f1_row4_col1\" class=\"data row4 col1\" >(1000, 8)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_5b1f1_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
              "      <td id=\"T_5b1f1_row5_col1\" class=\"data row5 col1\" >(1000, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_5b1f1_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
              "      <td id=\"T_5b1f1_row6_col1\" class=\"data row6 col1\" >(800, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_5b1f1_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
              "      <td id=\"T_5b1f1_row7_col1\" class=\"data row7 col1\" >(200, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_5b1f1_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
              "      <td id=\"T_5b1f1_row8_col1\" class=\"data row8 col1\" >6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_5b1f1_row9_col0\" class=\"data row9 col0\" >Categorical features</td>\n",
              "      <td id=\"T_5b1f1_row9_col1\" class=\"data row9 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_5b1f1_row10_col0\" class=\"data row10 col0\" >Preprocess</td>\n",
              "      <td id=\"T_5b1f1_row10_col1\" class=\"data row10 col1\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_5b1f1_row11_col0\" class=\"data row11 col0\" >Imputation type</td>\n",
              "      <td id=\"T_5b1f1_row11_col1\" class=\"data row11 col1\" >simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "      <td id=\"T_5b1f1_row12_col0\" class=\"data row12 col0\" >Numeric imputation</td>\n",
              "      <td id=\"T_5b1f1_row12_col1\" class=\"data row12 col1\" >mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "      <td id=\"T_5b1f1_row13_col0\" class=\"data row13 col0\" >Categorical imputation</td>\n",
              "      <td id=\"T_5b1f1_row13_col1\" class=\"data row13 col1\" >mode</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "      <td id=\"T_5b1f1_row14_col0\" class=\"data row14 col0\" >Maximum one-hot encoding</td>\n",
              "      <td id=\"T_5b1f1_row14_col1\" class=\"data row14 col1\" >25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "      <td id=\"T_5b1f1_row15_col0\" class=\"data row15 col0\" >Encoding method</td>\n",
              "      <td id=\"T_5b1f1_row15_col1\" class=\"data row15 col1\" >None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "      <td id=\"T_5b1f1_row16_col0\" class=\"data row16 col0\" >Remove multicollinearity</td>\n",
              "      <td id=\"T_5b1f1_row16_col1\" class=\"data row16 col1\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "      <td id=\"T_5b1f1_row17_col0\" class=\"data row17 col0\" >Multicollinearity threshold</td>\n",
              "      <td id=\"T_5b1f1_row17_col1\" class=\"data row17 col1\" >0.950000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "      <td id=\"T_5b1f1_row18_col0\" class=\"data row18 col0\" >Transformation</td>\n",
              "      <td id=\"T_5b1f1_row18_col1\" class=\"data row18 col1\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
              "      <td id=\"T_5b1f1_row19_col0\" class=\"data row19 col0\" >Transformation method</td>\n",
              "      <td id=\"T_5b1f1_row19_col1\" class=\"data row19 col1\" >yeo-johnson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
              "      <td id=\"T_5b1f1_row20_col0\" class=\"data row20 col0\" >Normalize</td>\n",
              "      <td id=\"T_5b1f1_row20_col1\" class=\"data row20 col1\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
              "      <td id=\"T_5b1f1_row21_col0\" class=\"data row21 col0\" >Normalize method</td>\n",
              "      <td id=\"T_5b1f1_row21_col1\" class=\"data row21 col1\" >zscore</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
              "      <td id=\"T_5b1f1_row22_col0\" class=\"data row22 col0\" >Feature selection</td>\n",
              "      <td id=\"T_5b1f1_row22_col1\" class=\"data row22 col1\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
              "      <td id=\"T_5b1f1_row23_col0\" class=\"data row23 col0\" >Feature selection method</td>\n",
              "      <td id=\"T_5b1f1_row23_col1\" class=\"data row23 col1\" >classic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
              "      <td id=\"T_5b1f1_row24_col0\" class=\"data row24 col0\" >Feature selection estimator</td>\n",
              "      <td id=\"T_5b1f1_row24_col1\" class=\"data row24 col1\" >lightgbm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
              "      <td id=\"T_5b1f1_row25_col0\" class=\"data row25 col0\" >Number of features selected</td>\n",
              "      <td id=\"T_5b1f1_row25_col1\" class=\"data row25 col1\" >0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
              "      <td id=\"T_5b1f1_row26_col0\" class=\"data row26 col0\" >Fold Generator</td>\n",
              "      <td id=\"T_5b1f1_row26_col1\" class=\"data row26 col1\" >StratifiedKFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
              "      <td id=\"T_5b1f1_row27_col0\" class=\"data row27 col0\" >Fold Number</td>\n",
              "      <td id=\"T_5b1f1_row27_col1\" class=\"data row27 col1\" >10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
              "      <td id=\"T_5b1f1_row28_col0\" class=\"data row28 col0\" >CPU Jobs</td>\n",
              "      <td id=\"T_5b1f1_row28_col1\" class=\"data row28 col1\" >-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
              "      <td id=\"T_5b1f1_row29_col0\" class=\"data row29 col0\" >Use GPU</td>\n",
              "      <td id=\"T_5b1f1_row29_col1\" class=\"data row29 col1\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
              "      <td id=\"T_5b1f1_row30_col0\" class=\"data row30 col0\" >Log Experiment</td>\n",
              "      <td id=\"T_5b1f1_row30_col1\" class=\"data row30 col1\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
              "      <td id=\"T_5b1f1_row31_col0\" class=\"data row31 col0\" >Experiment Name</td>\n",
              "      <td id=\"T_5b1f1_row31_col1\" class=\"data row31 col1\" >clf-default-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b1f1_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
              "      <td id=\"T_5b1f1_row32_col0\" class=\"data row32 col0\" >USI</td>\n",
              "      <td id=\"T_5b1f1_row32_col1\" class=\"data row32 col1\" >3bd4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x165d75900>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ PyCaret setup completed!\n",
            "\n",
            "Training samples: 800\n",
            "Test samples: 200\n"
          ]
        }
      ],
      "source": [
        "# Initialize PyCaret CLASSIFICATION environment \n",
        "clf = setup(  \n",
        "    data=train_data,\n",
        "    target='Recruiter_Decision',  \n",
        "    test_data=test_data,\n",
        "    session_id=42,\n",
        "    normalize=True,\n",
        "    transformation=True,\n",
        "    feature_selection=True,\n",
        "    remove_multicollinearity=True,\n",
        "    multicollinearity_threshold=0.95,\n",
        "    remove_outliers=False,\n",
        "    fix_imbalance=False,\n",
        "    verbose=True,\n",
        "    index=False\n",
        ")\n",
        "\n",
        "print(\"✓ PyCaret setup completed!\")\n",
        "print(f\"\\nTraining samples: {len(train_data)}\")\n",
        "print(f\"Test samples: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Compare Models\n",
        "\n",
        "Compare multiple regression models to find the best one for predicting AI Score.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available classification models in PyCaret:\n",
            "                                     Name  \\\n",
            "ID                                          \n",
            "lr                    Logistic Regression   \n",
            "knn                K Neighbors Classifier   \n",
            "nb                            Naive Bayes   \n",
            "dt               Decision Tree Classifier   \n",
            "svm                   SVM - Linear Kernel   \n",
            "rbfsvm                SVM - Radial Kernel   \n",
            "gpc           Gaussian Process Classifier   \n",
            "mlp                        MLP Classifier   \n",
            "ridge                    Ridge Classifier   \n",
            "rf               Random Forest Classifier   \n",
            "qda       Quadratic Discriminant Analysis   \n",
            "ada                  Ada Boost Classifier   \n",
            "gbc          Gradient Boosting Classifier   \n",
            "lda          Linear Discriminant Analysis   \n",
            "et                 Extra Trees Classifier   \n",
            "lightgbm  Light Gradient Boosting Machine   \n",
            "dummy                    Dummy Classifier   \n",
            "\n",
            "                                                  Reference  Turbo  \n",
            "ID                                                                  \n",
            "lr        sklearn.linear_model._logistic.LogisticRegression   True  \n",
            "knn       sklearn.neighbors._classification.KNeighborsCl...   True  \n",
            "nb                           sklearn.naive_bayes.GaussianNB   True  \n",
            "dt             sklearn.tree._classes.DecisionTreeClassifier   True  \n",
            "svm       sklearn.linear_model._stochastic_gradient.SGDC...   True  \n",
            "rbfsvm                             sklearn.svm._classes.SVC  False  \n",
            "gpc       sklearn.gaussian_process._gpc.GaussianProcessC...  False  \n",
            "mlp       sklearn.neural_network._multilayer_perceptron....  False  \n",
            "ridge           sklearn.linear_model._ridge.RidgeClassifier   True  \n",
            "rf          sklearn.ensemble._forest.RandomForestClassifier   True  \n",
            "qda       sklearn.discriminant_analysis.QuadraticDiscrim...   True  \n",
            "ada       sklearn.ensemble._weight_boosting.AdaBoostClas...   True  \n",
            "gbc         sklearn.ensemble._gb.GradientBoostingClassifier   True  \n",
            "lda       sklearn.discriminant_analysis.LinearDiscrimina...   True  \n",
            "et            sklearn.ensemble._forest.ExtraTreesClassifier   True  \n",
            "lightgbm                    lightgbm.sklearn.LGBMClassifier   True  \n",
            "dummy                         sklearn.dummy.DummyClassifier   True  \n"
          ]
        }
      ],
      "source": [
        "# Check available classification models\n",
        "from pycaret.classification import models\n",
        "\n",
        "available_models = models()\n",
        "print(\"Available classification models in PyCaret:\")\n",
        "print(available_models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Model comparison completed!\n",
            "\n",
            "Top 5 models selected based on AUC\n"
          ]
        }
      ],
      "source": [
        "# Compare CLASSIFICATION models and select top performers \n",
        "best_models = compare_models(\n",
        "    include=['rf','lightgbm', 'et', 'ada', 'dt', 'lr', 'ridge', 'nb', 'knn'], \n",
        "    sort='AUC', \n",
        "    n_select=5,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "print(\"✓ Model comparison completed!\")\n",
        "print(f\"\\nTop 5 models selected based on AUC\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model: LGBMClassifier\n",
            "\n",
            "Model performance on test set:\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "779b95d717cd422791d267f04799908d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Pipeline Plot', 'pipelin…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get the best model (lowest RMSE)\n",
        "best_model = best_models[0] if isinstance(best_models, list) else best_models\n",
        "\n",
        "print(f\"Best model: {type(best_model).__name__}\")\n",
        "print(\"\\nModel performance on test set:\")\n",
        "evaluate_model(best_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Model Tuning (Optional)\n",
        "\n",
        "Fine-tune the best model to improve performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Model tuning completed!\n",
            "\n",
            "Tuned model: LGBMClassifier\n",
            "\n",
            "Tuned model performance:\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7abaee3a5210414cac246424ed77b2ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Pipeline Plot', 'pipelin…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Tune the best model\n",
        "tuned_model = tune_model(best_model, optimize='AUC', n_iter=50, verbose=False)\n",
        "\n",
        "print(\"✓ Model tuning completed!\")\n",
        "print(f\"\\nTuned model: {type(tuned_model).__name__}\")\n",
        "print(\"\\nTuned model performance:\")\n",
        "evaluate_model(tuned_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Final Model Selection\n",
        "\n",
        "Select the final model (tuned or original) and evaluate on test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_d16a3\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_d16a3_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_d16a3_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
              "      <th id=\"T_d16a3_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
              "      <th id=\"T_d16a3_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
              "      <th id=\"T_d16a3_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
              "      <th id=\"T_d16a3_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
              "      <th id=\"T_d16a3_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
              "      <th id=\"T_d16a3_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_d16a3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_d16a3_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
              "      <td id=\"T_d16a3_row0_col1\" class=\"data row0 col1\" >0.7550</td>\n",
              "      <td id=\"T_d16a3_row0_col2\" class=\"data row0 col2\" >0.5175</td>\n",
              "      <td id=\"T_d16a3_row0_col3\" class=\"data row0 col3\" >0.7550</td>\n",
              "      <td id=\"T_d16a3_row0_col4\" class=\"data row0 col4\" >0.6935</td>\n",
              "      <td id=\"T_d16a3_row0_col5\" class=\"data row0 col5\" >0.7174</td>\n",
              "      <td id=\"T_d16a3_row0_col6\" class=\"data row0 col6\" >0.0196</td>\n",
              "      <td id=\"T_d16a3_row0_col7\" class=\"data row0 col7\" >0.0216</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x166682d10>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "FINAL MODEL PERFORMANCE METRICS\n",
            "============================================================\n",
            "\n",
            "Model Type: LGBMClassifier\n",
            "\n",
            "Classification Metrics (Recruiter Decision Prediction):\n",
            "  Accuracy:  0.7550\n",
            "  Precision: 0.8077\n",
            "  Recall:    0.9130\n",
            "  F1 Score:  0.8571\n",
            "  AUC-ROC:   0.5207\n",
            "\n",
            "Confusion Matrix:\n",
            "[[147  14]\n",
            " [ 35   4]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Hire       0.81      0.91      0.86       161\n",
            "      Reject       0.22      0.10      0.14        39\n",
            "\n",
            "    accuracy                           0.76       200\n",
            "   macro avg       0.51      0.51      0.50       200\n",
            "weighted avg       0.69      0.76      0.72       200\n",
            "\n",
            "\n",
            "Test Set Size: 200 samples\n",
            "Class Distribution: {'Hire': 161, 'Reject': 39}\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Use tuned model if it performs better, otherwise use original\n",
        "#in our case tuned_model performed worse, so we consider best_model\n",
        "final_model = best_model\n",
        "\n",
        "# Make predictions on test set\n",
        "predictions = predict_model(final_model, data=test_data)\n",
        "\n",
        "# Calculate CLASSIFICATION metrics \n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "\n",
        "y_true = test_data['Recruiter_Decision'].values  \n",
        "y_pred = predictions['prediction_label'].values\n",
        "y_pred_proba = predictions['prediction_score'].values if 'prediction_score' in predictions.columns else None\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, pos_label='Hire')  \n",
        "recall = recall_score(y_true, y_pred, pos_label='Hire')       \n",
        "f1 = f1_score(y_true, y_pred, pos_label='Hire')               \n",
        "\n",
        "# AUC requires probability scores\n",
        "if y_pred_proba is not None:\n",
        "    # Convert labels to binary (Hire=1, Reject=0)\n",
        "    y_true_binary = (y_true == 'Hire').astype(int)\n",
        "    auc = roc_auc_score(y_true_binary, y_pred_proba)\n",
        "else:\n",
        "    auc = None\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FINAL MODEL PERFORMANCE METRICS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nModel Type: {type(final_model).__name__}\")\n",
        "print(f\"\\nClassification Metrics (Recruiter Decision Prediction):\")  \n",
        "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"  Precision: {precision:.4f}\")\n",
        "print(f\"  Recall:    {recall:.4f}\")\n",
        "print(f\"  F1 Score:  {f1:.4f}\")\n",
        "if auc is not None:\n",
        "    print(f\"  AUC-ROC:   {auc:.4f}\")\n",
        "\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "print(f\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "print(f\"\\nTest Set Size: {len(y_true)} samples\")\n",
        "print(f\"Class Distribution: {pd.Series(y_true).value_counts().to_dict()}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Metrics Summary:\n",
            "  model_type: LGBMClassifier\n",
            "  accuracy: 0.755\n",
            "  precision: 0.8076923076923077\n",
            "  recall: 0.9130434782608695\n",
            "  f1_score: 0.8571428571428571\n",
            "  auc: 0.520703933747412\n",
            "  test_samples: 200\n",
            "  target_variable: Recruiter_Decision\n",
            "  task_type: classification\n",
            "  positive_class: Hire\n",
            "  class_distribution: {'Hire': 161, 'Reject': 39}\n"
          ]
        }
      ],
      "source": [
        "# Store metrics in a dictionary\n",
        "metrics = {\n",
        "    'model_type': type(final_model).__name__,\n",
        "    'accuracy': float(accuracy),\n",
        "    'precision': float(precision),\n",
        "    'recall': float(recall),\n",
        "    'f1_score': float(f1),\n",
        "    'auc': float(auc) if auc is not None else None,\n",
        "    'test_samples': int(len(y_true)),\n",
        "    'target_variable': 'Recruiter_Decision',  \n",
        "    'task_type': 'classification',  \n",
        "    'positive_class': 'Hire',  \n",
        "    'class_distribution': pd.Series(y_true).value_counts().to_dict()  \n",
        "}\n",
        "\n",
        "# Display metrics\n",
        "print(\"\\nMetrics Summary:\")\n",
        "for key, value in metrics.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our baseline hiring model (LGBM Classifier) achieves respectable precision and recall (~0.91), indicating reasonable predictive ability. However, the low AUC (0.52) reflects limited discrimination between Hire and Reject classes because the dataset is highly imbalanced (161 Hire vs. 39 Reject). This is realistic for HR scenarios, where models often overpredict hires due to skewed training data. This imperfect model is ideal for our FairHire system, which aims to evaluate fairness, detect bias, and monitor drift—rather than optimize predictive performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Save Model and Metrics\n",
        "\n",
        "Save the trained model and evaluation metrics for later use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformation Pipeline and Model Successfully Saved\n",
            "✓ Model saved as 'modelB_final.pkl'\n",
            "  (PyCaret automatically saves the model with preprocessing pipeline)\n"
          ]
        }
      ],
      "source": [
        "# Save the final model\n",
        "save_model(final_model, 'model_B/modelB_final')\n",
        "\n",
        "print(\"✓ Model saved as 'modelB_final.pkl'\")\n",
        "print(\"  (PyCaret automatically saves the model with preprocessing pipeline)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Metrics saved to 'modelB_metrics.json'\n",
            "\n",
            "Saved metrics:\n",
            "{\n",
            "  \"model_type\": \"LGBMClassifier\",\n",
            "  \"accuracy\": 0.755,\n",
            "  \"precision\": 0.8076923076923077,\n",
            "  \"recall\": 0.9130434782608695,\n",
            "  \"f1_score\": 0.8571428571428571,\n",
            "  \"auc\": 0.520703933747412,\n",
            "  \"test_samples\": 200,\n",
            "  \"target_variable\": \"Recruiter_Decision\",\n",
            "  \"task_type\": \"classification\",\n",
            "  \"positive_class\": \"Hire\",\n",
            "  \"class_distribution\": {\n",
            "    \"Hire\": 161,\n",
            "    \"Reject\": 39\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Save metrics to JSON file\n",
        "with open('model_B/modelB_metrics.json', 'w') as f:\n",
        "    json.dump(metrics, f, indent=4)\n",
        "\n",
        "print(\"✓ Metrics saved to 'modelB_metrics.json'\")\n",
        "print(\"\\nSaved metrics:\")\n",
        "print(json.dumps(metrics, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===================================================\n",
            "Building Model B shortlist base for all candidates\n",
            "===================================================\n",
            "Loading Model B...\n",
            "Transformation Pipeline and Model Successfully Loaded\n",
            "✓ Model A loaded successfully\n",
            "✓ Loaded Dataset_A_processed.csv with shape: (1000, 13)\n",
            "✓ All 7 feature columns present\n",
            "Making predictions on all candidates...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_d6349\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_d6349_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_d6349_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
              "      <th id=\"T_d6349_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
              "      <th id=\"T_d6349_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
              "      <th id=\"T_d6349_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
              "      <th id=\"T_d6349_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
              "      <th id=\"T_d6349_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
              "      <th id=\"T_d6349_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_d6349_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_d6349_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
              "      <td id=\"T_d6349_row0_col1\" class=\"data row0 col1\" >0.8180</td>\n",
              "      <td id=\"T_d6349_row0_col2\" class=\"data row0 col2\" >0.7874</td>\n",
              "      <td id=\"T_d6349_row0_col3\" class=\"data row0 col3\" >0.8180</td>\n",
              "      <td id=\"T_d6349_row0_col4\" class=\"data row0 col4\" >0.7861</td>\n",
              "      <td id=\"T_d6349_row0_col5\" class=\"data row0 col5\" >0.7756</td>\n",
              "      <td id=\"T_d6349_row0_col6\" class=\"data row0 col6\" >0.2017</td>\n",
              "      <td id=\"T_d6349_row0_col7\" class=\"data row0 col7\" >0.2514</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x166582800>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Predictions complete:\n",
            "  - Predicted Hire: 943 (94.3%)\n",
            "  - Predicted Reject: 57 (5.7%)\n",
            "\n",
            "✓ Shortlist base created:\n",
            "  - Total candidates: 1000\n",
            "  - Rank range: 1 to 997\n",
            "  - Top candidate hire probability: 0.986\n",
            "  - Bottom candidate hire probability: 0.505\n",
            "\n",
            "✓ Saved: model_B/modelB_shortlist_base.csv\n",
            "Columns: ['Skills', 'Experience', 'Education', 'Certifications', 'Job_Role', 'Salary_Expectation', 'Projects_Count', 'AI_Score', 'Recruiter_Decision', 'Education_Ordinal', 'Certifications_Encoded', 'Job_Role_Encoded', 'Education_Encoded', 'ModelB_Hire_Prob', 'ModelB_Prediction', 'ModelB_Pred_Label', 'ModelB_Rank']\n",
            "\n",
            "🏆 Top 5 Candidates (Highest Hire Probability):\n",
            "     ModelB_Rank               Job_Role  Experience  Education_Ordinal  \\\n",
            "920            1      Software Engineer           9                  2   \n",
            "663            1  Cybersecurity Analyst           6                  3   \n",
            "348            1         Data Scientist           1                  3   \n",
            "535            1      Software Engineer           4                  4   \n",
            "786            1         Data Scientist           9                  2   \n",
            "\n",
            "     ModelB_Hire_Prob ModelB_Pred_Label  \n",
            "920            0.9856              Hire  \n",
            "663            0.9856              Hire  \n",
            "348            0.9856              Hire  \n",
            "535            0.9856              Hire  \n",
            "786            0.9856              Hire  \n",
            "\n",
            "📉 Bottom 5 Candidates (Lowest Hire Probability):\n",
            "     ModelB_Rank               Job_Role  Experience  Education_Ordinal  \\\n",
            "911          992          AI Researcher           6                  3   \n",
            "72           997         Data Scientist           0                  3   \n",
            "196          997         Data Scientist           8                  4   \n",
            "379          997         Data Scientist           2                  2   \n",
            "485          997  Cybersecurity Analyst           8                  2   \n",
            "\n",
            "     ModelB_Hire_Prob ModelB_Pred_Label  \n",
            "911            0.5105            Reject  \n",
            "72             0.5048              Hire  \n",
            "196            0.5048              Hire  \n",
            "379            0.5048              Hire  \n",
            "485            0.5048              Hire  \n",
            "\n",
            "===================================================\n",
            "✅ Model A shortlist base complete!\n",
            "===================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pycaret.classification import load_model, predict_model\n",
        "\n",
        "print(\"\\n===================================================\")\n",
        "print(\"Building Model B shortlist base for all candidates\")\n",
        "print(\"===================================================\")\n",
        "\n",
        "# ============================================================\n",
        "# 1. Load Model B using PyCaret's load_model (includes preprocessing)\n",
        "# ============================================================\n",
        "print(\"Loading Model B...\")\n",
        "modelB = load_model('model_B/modelB_final')  \n",
        "print(\"✓ Model A loaded successfully\")\n",
        "\n",
        "# ============================================================\n",
        "# 2. Load full processed dataset\n",
        "# ============================================================\n",
        "full_df = pd.read_csv(\"model_B/Dataset_B_processed.csv\")\n",
        "print(f\"✓ Loaded Dataset_A_processed.csv with shape: {full_df.shape}\")\n",
        "\n",
        "# ============================================================\n",
        "# 3. Prepare data for prediction (need target column for PyCaret)\n",
        "# ============================================================\n",
        "# PyCaret expects the target column to be present (even if we ignore it)\n",
        "# Create a dummy target column if it doesn't exist\n",
        "if 'Recruiter_Decision' not in full_df.columns:\n",
        "    full_df['Recruiter_Decision'] = 'Hire'  # Dummy value\n",
        "\n",
        "# Feature columns that were used in training\n",
        "feature_columns = [\n",
        "    'Skills', \n",
        "    'Experience', \n",
        "    'Education_Ordinal', \n",
        "    'Certifications_Encoded', \n",
        "    'Job_Role_Encoded', \n",
        "    'Salary_Expectation', \n",
        "    'Projects_Count'\n",
        "]\n",
        "\n",
        "# Sanity check: make sure all feature columns exist\n",
        "missing_feats = [c for c in feature_columns if c not in full_df.columns]\n",
        "if missing_feats:\n",
        "    print(f\"⚠️ Missing feature columns in Dataset_A_processed: {missing_feats}\")\n",
        "    raise ValueError(\"Feature columns mismatch between training and full dataset.\")\n",
        "\n",
        "print(f\"✓ All {len(feature_columns)} feature columns present\")\n",
        "\n",
        "# ============================================================\n",
        "# 4. Make predictions using PyCaret's predict_model\n",
        "# ============================================================\n",
        "print(\"Making predictions on all candidates...\")\n",
        "predictions = predict_model(modelB, data=full_df)\n",
        "\n",
        "# Extract predictions and probabilities\n",
        "pred_labels = predictions['prediction_label'].values\n",
        "pred_scores = predictions['prediction_score'].values  # This is P(Hire)\n",
        "\n",
        "# Convert labels to binary\n",
        "label_map = {'Hire': 1, 'Reject': 0}\n",
        "pred_binary = predictions['prediction_label'].map(label_map).fillna(0).astype(int).values\n",
        "\n",
        "print(f\"✓ Predictions complete:\")\n",
        "print(f\"  - Predicted Hire: {(pred_binary == 1).sum()} ({(pred_binary == 1).mean()*100:.1f}%)\")\n",
        "print(f\"  - Predicted Reject: {(pred_binary == 0).sum()} ({(pred_binary == 0).mean()*100:.1f}%)\")\n",
        "\n",
        "# ============================================================\n",
        "# 5. Build shortlist base DataFrame with rankings\n",
        "# ============================================================\n",
        "shortlist_base = full_df.copy()\n",
        "\n",
        "# Add prediction columns\n",
        "shortlist_base[\"ModelB_Hire_Prob\"] = pred_scores\n",
        "shortlist_base[\"ModelB_Prediction\"] = pred_binary\n",
        "shortlist_base[\"ModelB_Pred_Label\"] = predictions['prediction_label'].values\n",
        "\n",
        "# Add ranking based on hire probability (1 = highest probability)\n",
        "shortlist_base[\"ModelB_Rank\"] = shortlist_base[\"ModelB_Hire_Prob\"].rank(\n",
        "    ascending=False,  # Higher probability = better rank\n",
        "    method='min'      # Ties get same rank\n",
        ").astype(int)\n",
        "\n",
        "# Sort by rank for easy viewing\n",
        "shortlist_base = shortlist_base.sort_values('ModelB_Rank')\n",
        "\n",
        "print(f\"\\n✓ Shortlist base created:\")\n",
        "print(f\"  - Total candidates: {len(shortlist_base)}\")\n",
        "print(f\"  - Rank range: {shortlist_base['ModelB_Rank'].min()} to {shortlist_base['ModelB_Rank'].max()}\")\n",
        "print(f\"  - Top candidate hire probability: {shortlist_base['ModelB_Hire_Prob'].max():.3f}\")\n",
        "print(f\"  - Bottom candidate hire probability: {shortlist_base['ModelB_Hire_Prob'].min():.3f}\")\n",
        "\n",
        "# ============================================================\n",
        "# 6. Save to CSV for Streamlit app\n",
        "# ============================================================\n",
        "output_path = \"model_B/modelB_shortlist_base.csv\"\n",
        "shortlist_base.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"\\n✓ Saved: {output_path}\")\n",
        "print(f\"Columns: {shortlist_base.columns.tolist()}\")\n",
        "\n",
        "# ============================================================\n",
        "# 7. Display sample of top and bottom candidates\n",
        "# ============================================================\n",
        "print(\"\\n🏆 Top 5 Candidates (Highest Hire Probability):\")\n",
        "top_cols = ['ModelB_Rank', 'Job_Role', 'Experience', 'Education_Ordinal', \n",
        "            'ModelB_Hire_Prob', 'ModelB_Pred_Label']\n",
        "print(shortlist_base[top_cols].head())\n",
        "\n",
        "print(\"\\n📉 Bottom 5 Candidates (Lowest Hire Probability):\")\n",
        "print(shortlist_base[top_cols].tail())\n",
        "\n",
        "print(\"\\n===================================================\")\n",
        "print(\"✅ Model A shortlist base complete!\")\n",
        "print(\"===================================================\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#For streamlit UI implementation for top rank candidates for a job role...\n",
        "\n",
        "# Original columns from Dataset_A_processed.csv\n",
        "'Skills', 'Experience', 'Education_Ordinal', 'Certifications_Encoded', \n",
        "'Job_Role_Encoded', 'Salary_Expectation', 'Projects_Count', 'Recruiter_Decision'\n",
        "\n",
        "# NEW columns added:\n",
        "'ModelB_Hire_Prob'   # Probability of being hired (0.0 to 1.0)\n",
        "'ModelB_Prediction'  # Binary prediction (1=Hire, 0=Reject)\n",
        "'ModelB_Pred_Label'  # Text label ('Hire' or 'Reject')\n",
        "'ModelB_Rank'        # Ranking (1 = best candidate)\n",
        "\n",
        "# In your Streamlit app\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "\n",
        "# Load shortlist\n",
        "shortlist = pd.read_csv('model_B/modelB_shortlist_base.csv')\n",
        "\n",
        "# Filter by job role\n",
        "job_role = st.selectbox(\"Select Job Role\", shortlist['Job_Role'].unique())\n",
        "filtered = shortlist[shortlist['Job_Role_Encoded'] == job_role]\n",
        "\n",
        "# Show top K candidates\n",
        "top_k = st.slider(\"Number of candidates to show\", 10, 100, 50)\n",
        "top_candidates = filtered.nsmallest(top_k, 'ModelB_Rank')\n",
        "\n",
        "# Display with ranking\n",
        "st.dataframe(top_candidates[['ModelB_Rank', 'Skills', 'Experience', \n",
        "                              'Education_Ordinal', 'ModelB_Hire_Prob']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Model Visualization\n",
        "\n",
        "Visualize model performance and feature importance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Model plots saved in 'Plots' directory\n"
          ]
        }
      ],
      "source": [
        "plot_model(final_model, plot='auc', save=True)           # ROC-AUC curve\n",
        "plot_model(final_model, plot='confusion_matrix', save=True)  # Confusion matrix\n",
        "plot_model(final_model, plot='class_report', save=True)  # Classification report\n",
        "plot_model(final_model, plot='pr', save=True)            # Precision-Recall curve\n",
        "plot_model(final_model, plot='feature', save=True)       # Feature importance\n",
        "\n",
        "print(\"✓ Model plots saved in 'Plots' directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Summary\n",
        "\n",
        "Model A training completed! This model can now be used for:\n",
        "- Predicting AI Score based on resume features\n",
        "- Fairness analysis (using demographics_test and y_class_test from Data_processing.ipynb)\n",
        "- Comparison with other models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MODEL B TRAINING SUMMARY\n",
            "============================================================\n",
            "\n",
            "✓ Model Type: LGBMClassifier\n",
            "✓ Target Variable: Recruiter_Decision (Classification)\n",
            "✓ Positive Class: Hire\n",
            "✓ Test Set Performance:\n",
            "    Accuracy:  0.7550\n",
            "    Precision: 0.8077\n",
            "    Recall:    0.9130\n",
            "    F1 Score:  0.8571\n",
            "    AUC-ROC:   0.5207\n",
            "\n",
            "✓ Files Saved:\n",
            "    - modelB_final.pkl (trained model)\n",
            "    - modelB_metrics.json (evaluation metrics)\n",
            "    - modelB_predictions.csv (test set predictions)\n",
            "\n",
            "✓ Next Steps:\n",
            "    - Use this model for fairness analysis\n",
            "    - Compare predictions across demographic groups\n",
            "    - Analyze bias in Hire/Reject decisions\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"MODEL B TRAINING SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n✓ Model Type: {metrics['model_type']}\")\n",
        "print(f\"✓ Target Variable: {metrics['target_variable']} (Classification)\")  \n",
        "print(f\"✓ Positive Class: {metrics['positive_class']}\")  \n",
        "print(f\"✓ Test Set Performance:\")\n",
        "print(f\"    Accuracy:  {metrics['accuracy']:.4f}\")  \n",
        "print(f\"    Precision: {metrics['precision']:.4f}\") \n",
        "print(f\"    Recall:    {metrics['recall']:.4f}\")     \n",
        "print(f\"    F1 Score:  {metrics['f1_score']:.4f}\")   \n",
        "if metrics['auc'] is not None:\n",
        "    print(f\"    AUC-ROC:   {metrics['auc']:.4f}\")     \n",
        "print(f\"\\n✓ Files Saved:\")\n",
        "print(f\"    - modelB_final.pkl (trained model)\")\n",
        "print(f\"    - modelB_metrics.json (evaluation metrics)\")\n",
        "print(f\"    - modelB_predictions.csv (test set predictions)\")\n",
        "print(f\"\\n✓ Next Steps:\")\n",
        "print(f\"    - Use this model for fairness analysis\")\n",
        "print(f\"    - Compare predictions across demographic groups\")  \n",
        "print(f\"    - Analyze bias in Hire/Reject decisions\")         \n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Fairness Analysis\n",
        "\n",
        "- Importing fairness_util.py which adheres to fairness metrics from arXiv paper: https://arxiv.org/pdf/2405.19699 \n",
        "(Fairness in AI-Driven Recruitment: Challenges, Metrics, Methods, and Future Directions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "✅ FAIRNESS ANALYSIS FOR MODEL B\n",
            "======================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_9ce2f\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_9ce2f_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_9ce2f_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
              "      <th id=\"T_9ce2f_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
              "      <th id=\"T_9ce2f_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
              "      <th id=\"T_9ce2f_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
              "      <th id=\"T_9ce2f_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
              "      <th id=\"T_9ce2f_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
              "      <th id=\"T_9ce2f_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_9ce2f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_9ce2f_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
              "      <td id=\"T_9ce2f_row0_col1\" class=\"data row0 col1\" >0.7550</td>\n",
              "      <td id=\"T_9ce2f_row0_col2\" class=\"data row0 col2\" >0.5175</td>\n",
              "      <td id=\"T_9ce2f_row0_col3\" class=\"data row0 col3\" >0.7550</td>\n",
              "      <td id=\"T_9ce2f_row0_col4\" class=\"data row0 col4\" >0.6935</td>\n",
              "      <td id=\"T_9ce2f_row0_col5\" class=\"data row0 col5\" >0.7174</td>\n",
              "      <td id=\"T_9ce2f_row0_col6\" class=\"data row0 col6\" >0.0196</td>\n",
              "      <td id=\"T_9ce2f_row0_col7\" class=\"data row0 col7\" >0.0216</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x168fd5c00>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Fairness Analysis Setup:\n",
            "  - Test samples: 200\n",
            "  - Ground truth (Hire=1): 161 (80.5%)\n",
            "  - Model predicts (Hire=1): 182 (91.0%)\n",
            "  - Model accuracy: 75.5%\n",
            "\n",
            "✓ Fairness DataFrame:\n",
            "  - Shape: (200, 7)\n",
            "  - Demographics: ['Gender', 'Race', 'Age_Group', 'Disability_Status']\n",
            "\n",
            "======================================================================\n",
            "📊 Fairness Analysis by: Gender\n",
            "======================================================================\n",
            "\n",
            "Group distribution (kept groups):\n",
            "group\n",
            "Male      101\n",
            "Female     99\n",
            "Name: count, dtype: int64\n",
            "\n",
            "1️⃣ Demographic Parity (Hire Rate by Group):\n",
            "   Female: 89.9%\n",
            "   Male: 92.1%\n",
            "   ⚠️ Max gap: 2.2 percentage points (lower = fairer)\n",
            "\n",
            "2️⃣ Top-50 Selection Rate Parity:\n",
            "   Female: 23.2% in Top-50\n",
            "   Male: 26.7% in Top-50\n",
            "   Min/Max ratio: 0.869\n",
            "   ✅ PASS (4/5 rule: ≥ 0.80)\n",
            "\n",
            "3️⃣ Equal Opportunity (TPR among true Hires):\n",
            "   Female: 100.0%\n",
            "   Male: 100.0%\n",
            "   ⚠️ Max TPR gap: 0.0 percentage points\n",
            "\n",
            "4️⃣ Rank Ordering Bias (lower avg rank = appears earlier in shortlist):\n",
            "   Female: average rank 104.9\n",
            "   Male: average rank 96.2\n",
            "   ⚠️ Max rank gap: 8.7 positions\n",
            "\n",
            "======================================================================\n",
            "📊 Fairness Analysis by: Race\n",
            "======================================================================\n",
            "\n",
            "Group distribution (kept groups):\n",
            "group\n",
            "White       111\n",
            "Hispanic     36\n",
            "Black        33\n",
            "Asian        13\n",
            "Name: count, dtype: int64\n",
            "\n",
            "1️⃣ Demographic Parity (Hire Rate by Group):\n",
            "   Asian: 92.3%\n",
            "   Black: 93.9%\n",
            "   Hispanic: 88.9%\n",
            "   White: 90.1%\n",
            "   ⚠️ Max gap: 5.1 percentage points (lower = fairer)\n",
            "\n",
            "2️⃣ Top-50 Selection Rate Parity:\n",
            "   Asian: 38.5% in Top-50\n",
            "   Black: 27.3% in Top-50\n",
            "   Hispanic: 22.2% in Top-50\n",
            "   White: 25.2% in Top-50\n",
            "   Min/Max ratio: 0.578\n",
            "   ❌ FAIL (4/5 rule: < 0.80)\n",
            "\n",
            "3️⃣ Equal Opportunity (TPR among true Hires):\n",
            "   Asian: 100.0%\n",
            "   Black: 100.0%\n",
            "   Hispanic: 100.0%\n",
            "   White: 100.0%\n",
            "   ⚠️ Max TPR gap: 0.0 percentage points\n",
            "\n",
            "4️⃣ Rank Ordering Bias (lower avg rank = appears earlier in shortlist):\n",
            "   Asian: average rank 83.2\n",
            "   Black: average rank 99.8\n",
            "   Hispanic: average rank 90.2\n",
            "   White: average rank 100.0\n",
            "   ⚠️ Max rank gap: 16.7 positions\n",
            "\n",
            "======================================================================\n",
            "📊 Fairness Analysis by: Age_Group\n",
            "======================================================================\n",
            "\n",
            "Group distribution (kept groups):\n",
            "group\n",
            "18-29    103\n",
            "30-39     94\n",
            "40+        0\n",
            "Name: count, dtype: int64\n",
            "\n",
            "1️⃣ Demographic Parity (Hire Rate by Group):\n",
            "   18-29: 91.3%\n",
            "   30-39: 90.4%\n",
            "   40+: nan%\n",
            "   ⚠️ Max gap: nan percentage points (lower = fairer)\n",
            "\n",
            "2️⃣ Top-50 Selection Rate Parity:\n",
            "   18-29: 21.4% in Top-50\n",
            "   30-39: 29.8% in Top-50\n",
            "   40+: nan% in Top-50\n",
            "   Min/Max ratio: 0.000\n",
            "   ❌ FAIL (4/5 rule: < 0.80)\n",
            "\n",
            "3️⃣ Equal Opportunity (TPR among true Hires):\n",
            "   18-29: 100.0%\n",
            "   30-39: 100.0%\n",
            "   40+: N/A (no true positives)\n",
            "   ⚠️ Max TPR gap: 0.0 percentage points\n",
            "\n",
            "4️⃣ Rank Ordering Bias (lower avg rank = appears earlier in shortlist):\n",
            "   18-29: average rank 102.5\n",
            "   30-39: average rank 95.2\n",
            "   40+: average rank nan\n",
            "   ⚠️ Max rank gap: nan positions\n",
            "\n",
            "======================================================================\n",
            "📊 Fairness Analysis by: Disability_Status\n",
            "======================================================================\n",
            "\n",
            "Group distribution (kept groups):\n",
            "group\n",
            "No     188\n",
            "Yes     12\n",
            "Name: count, dtype: int64\n",
            "\n",
            "1️⃣ Demographic Parity (Hire Rate by Group):\n",
            "   No: 90.4%\n",
            "   Yes: 100.0%\n",
            "   ⚠️ Max gap: 9.6 percentage points (lower = fairer)\n",
            "\n",
            "2️⃣ Top-50 Selection Rate Parity:\n",
            "   No: 24.5% in Top-50\n",
            "   Yes: 33.3% in Top-50\n",
            "   Min/Max ratio: 0.734\n",
            "   ❌ FAIL (4/5 rule: < 0.80)\n",
            "\n",
            "3️⃣ Equal Opportunity (TPR among true Hires):\n",
            "   No: 100.0%\n",
            "   Yes: 100.0%\n",
            "   ⚠️ Max TPR gap: 0.0 percentage points\n",
            "\n",
            "4️⃣ Rank Ordering Bias (lower avg rank = appears earlier in shortlist):\n",
            "   No: average rank 101.1\n",
            "   Yes: average rank 91.2\n",
            "   ⚠️ Max rank gap: 9.8 positions\n",
            "\n",
            "======================================================================\n",
            "=== 📊 FAIRNESS SUMMARY FOR MODEL B (COMPACT) ===\n",
            "======================================================================\n",
            "\n",
            "🔍 Gender:\n",
            "   demographic_parity_max_gap: 0.0218\n",
            "   topk_min_over_max: 0.8691\n",
            "   equal_opportunity_max_gap: 0.0000\n",
            "   rank_ordering_max_gap: 8.6909\n",
            "   score_distribution_overlap: 0.7809\n",
            "\n",
            "🔍 Race:\n",
            "   demographic_parity_max_gap: 0.0505\n",
            "   topk_min_over_max: 0.5778\n",
            "   equal_opportunity_max_gap: 0.0000\n",
            "   rank_ordering_max_gap: 16.7422\n",
            "   score_distribution_overlap: N/A\n",
            "\n",
            "🔍 Age_Group:\n",
            "   demographic_parity_max_gap: nan\n",
            "   topk_min_over_max: 0.0000\n",
            "   equal_opportunity_max_gap: 0.0000\n",
            "   rank_ordering_max_gap: nan\n",
            "   score_distribution_overlap: 0.7870\n",
            "\n",
            "🔍 Disability_Status:\n",
            "   demographic_parity_max_gap: 0.0957\n",
            "   topk_min_over_max: 0.7340\n",
            "   equal_opportunity_max_gap: 0.0000\n",
            "   rank_ordering_max_gap: 9.8404\n",
            "   score_distribution_overlap: 0.4184\n",
            "\n",
            "✓ Saved: modelB_fairness_metrics.json\n",
            "✓ Updated: modelB_metrics.json\n",
            "\n",
            "======================================================================\n",
            "✅ FAIRNESS ANALYSIS COMPLETE!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "from fairness_util import (\n",
        "    demographic_parity_diff,\n",
        "    selection_rate_parity_topk,\n",
        "    rank_ordering_bias,\n",
        "    equal_opportunity_diff,\n",
        "    score_distribution_overlap,\n",
        ")\n",
        "\n",
        "print(\"\\n======================================================================\")\n",
        "print(\"✅ FAIRNESS ANALYSIS FOR MODEL B\")\n",
        "print(\"======================================================================\")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 1. Prepare ground truth, predictions, base fairness DataFrame\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "# Map Recruiter_Decision text -> binary 1/0\n",
        "label_map = {\"Hire\": 1, \"Reject\": 0, \"No hire\": 0, \"No Hire\": 0}\n",
        "\n",
        "# Get true labels from test_data\n",
        "y_true = test_data['Recruiter_Decision'].map(label_map).fillna(0).astype(int)\n",
        "\n",
        "# Get predictions from your PyCaret model\n",
        "predictions_full = predict_model(final_model, data=test_data)\n",
        "\n",
        "# Extract predicted labels\n",
        "y_pred_labels = predictions_full['prediction_label'].map(label_map).fillna(0).astype(int)\n",
        "y_pred = y_pred_labels.values\n",
        "\n",
        "# Extract probability of Hire class\n",
        "if 'prediction_score_Hire' in predictions_full.columns:\n",
        "    y_proba = predictions_full['prediction_score_Hire'].values\n",
        "elif 'prediction_score' in predictions_full.columns:\n",
        "    y_proba = predictions_full['prediction_score'].values\n",
        "else:\n",
        "    print(\"⚠️ Warning: Using fallback probability extraction\")\n",
        "    y_proba = predict_model(final_model, data=test_data, raw_score=True)['prediction_score'].values\n",
        "\n",
        "accuracy = (y_pred == y_true).mean()\n",
        "\n",
        "print(\"✓ Fairness Analysis Setup:\")\n",
        "print(f\"  - Test samples: {len(y_true)}\")\n",
        "print(f\"  - Ground truth (Hire=1): {y_true.sum()} ({y_true.mean()*100:.1f}%)\")\n",
        "print(f\"  - Model predicts (Hire=1): {y_pred.sum()} ({y_pred.mean()*100:.1f}%)\")\n",
        "print(f\"  - Model accuracy: {accuracy*100:.1f}%\")\n",
        "\n",
        "fair_df = pd.DataFrame({\n",
        "    \"y_true\":  y_true.values,\n",
        "    \"y_pred\":  y_pred,\n",
        "    \"y_proba\": y_proba,\n",
        "})\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 2. Clean demographics and attach to fairness DataFrame\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "# Load demographics if not already in memory\n",
        "if 'demographics_test' not in locals() or demographics_test is None:\n",
        "    try:\n",
        "        demographics_test = pd.read_csv('model_B/demographics_test_modelB.csv')\n",
        "        print(\"✓ Loaded demographics_test_modelB.csv\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"⚠️ Warning: demographics_test_modelB.csv not found!\")\n",
        "        demographics_test = pd.DataFrame()\n",
        "\n",
        "demo = demographics_test.copy()\n",
        "\n",
        "# Age -> bucket into coarse groups so output is readable\n",
        "if \"Age\" in demo.columns:\n",
        "    demo[\"Age_Group\"] = pd.cut(\n",
        "        demo[\"Age\"],\n",
        "        bins=[17, 29, 39, 120],\n",
        "        labels=[\"18-29\", \"30-39\", \"40+\"],\n",
        "        right=True,\n",
        "        include_lowest=True,\n",
        "    )\n",
        "\n",
        "# Race -> collapse rare categories into \"Other / Minority\"\n",
        "if \"Race\" in demo.columns:\n",
        "    race_counts = demo[\"Race\"].value_counts()\n",
        "    rare_races = race_counts[race_counts < 10].index  # threshold can be tuned\n",
        "    demo[\"Race_Grouped\"] = demo[\"Race\"].where(~demo[\"Race\"].isin(rare_races),\n",
        "                                              \"Other / Minority\")\n",
        "\n",
        "# Attach cleaned demographics using your original column names where possible\n",
        "if \"Gender\" in demo.columns:\n",
        "    fair_df[\"Gender\"] = demo[\"Gender\"].values\n",
        "if \"Race_Grouped\" in demo.columns:\n",
        "    fair_df[\"Race\"] = demo[\"Race_Grouped\"].values   # we overwrite Race with grouped\n",
        "elif \"Race\" in demo.columns:\n",
        "    fair_df[\"Race\"] = demo[\"Race\"].values\n",
        "if \"Age_Group\" in demo.columns:\n",
        "    fair_df[\"Age_Group\"] = demo[\"Age_Group\"].values\n",
        "if \"Disability_Status\" in demo.columns:\n",
        "    fair_df[\"Disability_Status\"] = demo[\"Disability_Status\"].values\n",
        "\n",
        "demographic_attrs = [\"Gender\", \"Race\", \"Age_Group\", \"Disability_Status\"]\n",
        "demographic_attrs = [a for a in demographic_attrs if a in fair_df.columns]\n",
        "\n",
        "print(\"\\n✓ Fairness DataFrame:\")\n",
        "print(f\"  - Shape: {fair_df.shape}\")\n",
        "print(f\"  - Demographics: {demographic_attrs}\")\n",
        "\n",
        "# Only report groups with at least this many samples\n",
        "MIN_GROUP_SIZE = 10\n",
        "\n",
        "def filter_small_groups(df, group_col, min_size=MIN_GROUP_SIZE):\n",
        "    counts = df[group_col].value_counts()\n",
        "    valid = counts[counts >= min_size].index\n",
        "    return df[df[group_col].isin(valid)], valid\n",
        "\n",
        "\n",
        "# ⚠️ FIX: Changed from fairness_summary_A to fairness_summary_B\n",
        "fairness_summary_B = {}\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 3. Per-attribute fairness metrics (clean, human-readable)\n",
        "# -------------------------------------------------------------------\n",
        "for attr in demographic_attrs:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"📊 Fairness Analysis by: {attr}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    df_attr = fair_df.copy()\n",
        "    df_attr[\"group\"] = df_attr[attr]\n",
        "\n",
        "    # Filter out tiny groups to avoid crazy 100%/0% stats from 1–2 rows\n",
        "    df_attr, kept_groups = filter_small_groups(df_attr, \"group\", MIN_GROUP_SIZE)\n",
        "    if len(kept_groups) < 2:\n",
        "        print(f\"⚠️ Not enough data for {attr} after filtering groups with <{MIN_GROUP_SIZE} samples. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    print(\"\\nGroup distribution (kept groups):\")\n",
        "    print(df_attr[\"group\"].value_counts())\n",
        "\n",
        "    # 1️⃣ Demographic Parity – use y_pred directly (hire rate by group)\n",
        "    dp = demographic_parity_diff(\n",
        "        df_attr,\n",
        "        group_col=\"group\",\n",
        "        score_col=\"y_pred\",  # mean of y_pred == hire rate\n",
        "        threshold=None,\n",
        "    )\n",
        "    print(\"\\n1️⃣ Demographic Parity (Hire Rate by Group):\")\n",
        "    for g, r in dp[\"per_group\"].items():\n",
        "        print(f\"   {g}: {r*100:.1f}%\")\n",
        "    print(f\"   ⚠️ Max gap: {dp['max_gap']*100:.1f} percentage points (lower = fairer)\")\n",
        "\n",
        "    # 2️⃣ Top-K Selection Rate Parity\n",
        "    top_k = min(50, len(df_attr))\n",
        "    srp = selection_rate_parity_topk(\n",
        "        df_attr,\n",
        "        group_col=\"group\",\n",
        "        score_col=\"y_proba\",\n",
        "        k=top_k,\n",
        "    )\n",
        "    print(f\"\\n2️⃣ Top-{top_k} Selection Rate Parity:\")\n",
        "    for g, r in srp[\"per_group\"].items():\n",
        "        print(f\"   {g}: {r*100:.1f}% in Top-{top_k}\")\n",
        "    print(f\"   Min/Max ratio: {srp['min_over_max']:.3f}\")\n",
        "    if srp[\"min_over_max\"] < 0.8:\n",
        "        print(\"   ❌ FAIL (4/5 rule: < 0.80)\")\n",
        "    else:\n",
        "        print(\"   ✅ PASS (4/5 rule: ≥ 0.80)\")\n",
        "\n",
        "    # 3️⃣ Equal Opportunity – TPR parity across groups\n",
        "    eo = equal_opportunity_diff(\n",
        "        df_attr,\n",
        "        group_col=\"group\",\n",
        "        y_true_col=\"y_true\",\n",
        "        score_col=\"y_proba\",\n",
        "        positive_label=1,\n",
        "        threshold=0.5,\n",
        "    )\n",
        "    print(\"\\n3️⃣ Equal Opportunity (TPR among true Hires):\")\n",
        "    for g, tpr in eo[\"per_group_tpr\"].items():\n",
        "        if np.isnan(tpr):\n",
        "            print(f\"   {g}: N/A (no true positives)\")\n",
        "        else:\n",
        "            print(f\"   {g}: {tpr*100:.1f}%\")\n",
        "    print(f\"   ⚠️ Max TPR gap: {eo['max_tpr_gap']*100:.1f} percentage points\")\n",
        "\n",
        "    # 4️⃣ Rank Ordering Bias\n",
        "    rob = rank_ordering_bias(\n",
        "        df_attr,\n",
        "        group_col=\"group\",\n",
        "        score_col=\"y_proba\",\n",
        "    )\n",
        "    print(\"\\n4️⃣ Rank Ordering Bias (lower avg rank = appears earlier in shortlist):\")\n",
        "    for g, r in rob[\"per_group_avg_rank\"].items():\n",
        "        print(f\"   {g}: average rank {r:.1f}\")\n",
        "    print(f\"   ⚠️ Max rank gap: {rob['max_rank_gap']:.1f} positions\")\n",
        "\n",
        "    # Optional score overlap if exactly 2 groups kept\n",
        "    kept_groups_list = list(kept_groups)\n",
        "    if len(kept_groups_list) == 2:\n",
        "        sdo = score_distribution_overlap(\n",
        "            df_attr,\n",
        "            group_a=kept_groups_list[0],\n",
        "            group_b=kept_groups_list[1],\n",
        "            group_col=\"group\",\n",
        "            score_col=\"y_proba\",\n",
        "            bins=20,\n",
        "        )\n",
        "    else:\n",
        "        sdo = None\n",
        "\n",
        "    # ⚠️ FIX: Changed from fairness_summary_A to fairness_summary_B\n",
        "    fairness_summary_B[attr] = {\n",
        "        \"demographic_parity_max_gap\": float(dp[\"max_gap\"]),\n",
        "        \"topk_min_over_max\": float(srp[\"min_over_max\"]),\n",
        "        \"equal_opportunity_max_gap\": float(eo[\"max_tpr_gap\"]) if not np.isnan(eo[\"max_tpr_gap\"]) else None,\n",
        "        \"rank_ordering_max_gap\": float(rob[\"max_rank_gap\"]),\n",
        "        \"score_distribution_overlap\": float(sdo) if sdo is not None else None,\n",
        "    }\n",
        "\n",
        "print(\"\\n======================================================================\")\n",
        "print(\"=== 📊 FAIRNESS SUMMARY FOR MODEL B (COMPACT) ===\")\n",
        "print(\"======================================================================\")\n",
        "for attr, metrics_dict in fairness_summary_B.items():\n",
        "    print(f\"\\n🔍 {attr}:\")\n",
        "    for k, v in metrics_dict.items():\n",
        "        if v is not None:\n",
        "            print(f\"   {k}: {v:.4f}\")\n",
        "        else:\n",
        "            print(f\"   {k}: N/A\")\n",
        "\n",
        "# ⚠️ FIX: Changed folder path from modelB/ to model_B/\n",
        "# Save summary to JSON\n",
        "with open(\"model_B/modelB_fairness_metrics.json\", \"w\") as f:\n",
        "    json.dump(fairness_summary_B, f, indent=2)\n",
        "print(\"\\n✓ Saved: modelB_fairness_metrics.json\")\n",
        "\n",
        "# Update main metrics file\n",
        "try:\n",
        "    with open(\"model_B/modelB_metrics.json\", \"r\") as f:\n",
        "        modelB_metrics = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    # ⚠️ FIX: Changed from modelA_metrics to modelB_metrics\n",
        "    modelB_metrics = {}\n",
        "\n",
        "modelB_metrics[\"fairness\"] = fairness_summary_B\n",
        "\n",
        "with open(\"model_B/modelB_metrics.json\", \"w\") as f:\n",
        "    json.dump(modelB_metrics, f, indent=2)\n",
        "\n",
        "print(\"✓ Updated: modelB_metrics.json\")\n",
        "\n",
        "print(\"\\n======================================================================\")\n",
        "print(\"✅ FAIRNESS ANALYSIS COMPLETE!\")\n",
        "print(\"======================================================================\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mlopsproj",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
